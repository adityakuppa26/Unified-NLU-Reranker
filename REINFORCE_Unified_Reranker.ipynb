{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "DiI-Y-5-8oqk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# helper functions\n",
        "def mock(num_utterances, num_hypotheses):\n",
        "  mock_X = np.random.rand(num_utterances, 3, num_hypotheses)\n",
        "  # make random hypothesis correct\n",
        "  mock_Y = np.eye(num_hypotheses)[np.random.choice(num_hypotheses, num_utterances)]\n",
        "  return mock_X, mock_Y\n",
        "\n",
        "def show_weights(policy_network):\n",
        "  for name, param in policy_network.named_parameters():\n",
        "    if param.requires_grad:\n",
        "      print(name, param.data)"
      ],
      "metadata": {
        "id": "wRBwXMD68xED"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy = torch.nn.Sequential(\n",
        "    torch.nn.Linear(3, 64),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(64, 1),\n",
        "    torch.nn.Softmax(dim=0)\n",
        ")\n",
        "lr = 0.005\n",
        "optim = torch.optim.SGD(policy.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "y7dSYeWa80y5"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Reinforce(X, Y, policy, epsilon_depth=5):\n",
        "  for x,y in zip(X,Y):\n",
        "    obs = torch.Tensor(x.T)\n",
        "    reward = 0\n",
        "    ground_truth = np.argmax(y)\n",
        "    \n",
        "    # sampling with epsilon depth strategy\n",
        "    probs = torch.flatten(policy(obs))\n",
        "    dist = torch.distributions.Categorical(probs=probs)\n",
        "    epsilon = epsilon_depth\n",
        "    while epsilon > 0:\n",
        "      best_action = torch.argmax(probs)\n",
        "      action = dist.sample().item()\n",
        "      if action == best_action:\n",
        "        break\n",
        "      else:\n",
        "        epsilon -= 1\n",
        "    \n",
        "    # reward inference\n",
        "    if action == ground_truth:\n",
        "      reward = 1\n",
        "\n",
        "    # update policy parameters\n",
        "    log_prob = dist.log_prob(torch.tensor(action, dtype=torch.int))\n",
        "    loss = - log_prob*reward\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()"
      ],
      "metadata": {
        "id": "SPpF_Qex-gQy"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mock_X, mock_Y = mock(1000, 6)\n",
        "Reinforce(mock_X, mock_Y, policy)"
      ],
      "metadata": {
        "id": "E4vhimQMI5o2"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_weights(policy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A--vIokWLnzb",
        "outputId": "5c11e9fc-b805-4aed-bca9-22d7023f842d"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.weight tensor([[-0.0437, -0.0183,  0.0625],\n",
            "        [ 0.1819,  0.3798,  0.3374],\n",
            "        [-0.3523,  0.1147, -0.2134],\n",
            "        [-0.2821,  0.1272,  0.2350],\n",
            "        [-0.2551, -0.5262, -0.0153],\n",
            "        [-0.5634, -0.5771,  0.2358],\n",
            "        [-0.1993, -0.4558, -0.5671],\n",
            "        [-0.1575,  0.0569,  0.2762],\n",
            "        [ 0.0601, -0.0345, -0.0258],\n",
            "        [-0.2387, -0.2367, -0.3468],\n",
            "        [ 0.0247,  0.4485, -0.3680],\n",
            "        [ 0.4356, -0.5701,  0.4917],\n",
            "        [-0.4654,  0.3924, -0.2727],\n",
            "        [-0.2327,  0.5218, -0.4392],\n",
            "        [-0.3631, -0.5730, -0.3485],\n",
            "        [ 0.3869, -0.0382,  0.4705],\n",
            "        [-0.4228, -0.0621, -0.5355],\n",
            "        [ 0.2559,  0.5083,  0.5192],\n",
            "        [ 0.2822,  0.0474,  0.2098],\n",
            "        [ 0.0037, -0.2619, -0.0835],\n",
            "        [-0.4801, -0.0810, -0.2359],\n",
            "        [-0.3143,  0.0900, -0.1902],\n",
            "        [ 0.1163,  0.4216,  0.1402],\n",
            "        [-0.1890,  0.1769,  0.5564],\n",
            "        [ 0.1310,  0.4633,  0.0240],\n",
            "        [ 0.4634,  0.0628,  0.1605],\n",
            "        [ 0.1910,  0.5394, -0.3573],\n",
            "        [-0.2237, -0.5153, -0.0704],\n",
            "        [ 0.5284,  0.2055,  0.4818],\n",
            "        [-0.3747, -0.5532, -0.0781],\n",
            "        [-0.4064,  0.5790,  0.0737],\n",
            "        [-0.2067, -0.0673,  0.2015],\n",
            "        [-0.4855,  0.0707,  0.5464],\n",
            "        [-0.4636, -0.0264, -0.1331],\n",
            "        [ 0.0605, -0.5515,  0.1066],\n",
            "        [-0.3750, -0.0524,  0.1602],\n",
            "        [ 0.4471,  0.1157, -0.3473],\n",
            "        [ 0.1403,  0.4929, -0.4880],\n",
            "        [ 0.0069,  0.0150,  0.0166],\n",
            "        [-0.4669,  0.2443,  0.2556],\n",
            "        [-0.5007, -0.4678,  0.3117],\n",
            "        [ 0.2783, -0.0715,  0.4328],\n",
            "        [-0.4853, -0.4633, -0.5415],\n",
            "        [-0.1241,  0.3228, -0.1274],\n",
            "        [ 0.3209, -0.1687, -0.0954],\n",
            "        [-0.1264, -0.3610, -0.2222],\n",
            "        [ 0.5104, -0.0436,  0.0292],\n",
            "        [-0.2071,  0.1890, -0.4408],\n",
            "        [ 0.3606,  0.2339,  0.0948],\n",
            "        [-0.1205,  0.0751, -0.2795],\n",
            "        [ 0.4226,  0.0288,  0.4383],\n",
            "        [-0.2927, -0.0770,  0.5627],\n",
            "        [-0.5134,  0.2915, -0.0914],\n",
            "        [-0.4246,  0.4938, -0.4107],\n",
            "        [-0.1859, -0.1640,  0.2853],\n",
            "        [-0.3162,  0.3366, -0.0863],\n",
            "        [-0.3354,  0.1833, -0.5308],\n",
            "        [-0.5594, -0.3101, -0.4302],\n",
            "        [ 0.2192, -0.0542, -0.5198],\n",
            "        [-0.4204, -0.2273, -0.3344],\n",
            "        [ 0.2101, -0.4985,  0.3527],\n",
            "        [-0.1801, -0.3277, -0.3270],\n",
            "        [-0.4141, -0.4124,  0.1278],\n",
            "        [ 0.2696,  0.1538,  0.1974]])\n",
            "0.bias tensor([ 0.0629,  0.3388,  0.3217,  0.5413, -0.3833, -0.0615,  0.4929, -0.4042,\n",
            "        -0.0263, -0.0945,  0.2782, -0.4758,  0.3214,  0.0245,  0.4008, -0.1267,\n",
            "        -0.0849,  0.4900, -0.4226, -0.5751,  0.4553,  0.4600, -0.0794,  0.3805,\n",
            "         0.2039, -0.0873, -0.5698, -0.5008,  0.2765, -0.3796,  0.2650, -0.5266,\n",
            "        -0.3928,  0.4008, -0.5140, -0.0407, -0.2723, -0.3307, -0.0054, -0.4392,\n",
            "         0.0158,  0.4423, -0.1270,  0.2673, -0.5487,  0.4733, -0.1626, -0.2148,\n",
            "         0.5693, -0.4212, -0.1557,  0.2698, -0.2449, -0.1229, -0.1960,  0.5492,\n",
            "         0.0674, -0.4337, -0.5318,  0.1319, -0.4805, -0.1941, -0.0118,  0.3787])\n",
            "2.weight tensor([[-6.5373e-02, -2.0384e-01,  1.0525e-01,  4.1137e-02, -6.6399e-02,\n",
            "         -2.8795e-02,  5.5573e-02, -4.3854e-02,  2.2872e-02, -5.6203e-02,\n",
            "         -8.1460e-02, -6.0117e-02,  1.1101e-02, -9.9636e-02,  1.8408e-02,\n",
            "         -5.6667e-02,  2.3526e-02, -6.3331e-02, -3.5013e-02,  9.6083e-02,\n",
            "          1.3446e-01,  5.9460e-02, -3.3134e-02, -6.6965e-02, -1.5326e-01,\n",
            "         -8.8717e-02,  1.3745e-02, -1.0616e-01, -2.1691e-01, -9.4810e-02,\n",
            "         -1.6705e-01,  3.3863e-02,  1.1838e-01,  8.8746e-02,  5.4813e-02,\n",
            "          1.0584e-01,  5.8298e-02,  1.8482e-02,  8.8140e-02,  2.4673e-02,\n",
            "         -1.2261e-01, -1.5144e-01, -6.3784e-02, -8.9516e-05,  5.3405e-02,\n",
            "          5.2122e-02, -5.1919e-02,  8.4512e-02, -8.2865e-02, -8.8400e-02,\n",
            "         -6.1406e-02, -1.2670e-01, -3.4406e-02, -1.1898e-01, -1.9697e-03,\n",
            "         -6.7311e-02, -1.1702e-01, -4.9444e-02, -6.5578e-02,  9.8974e-02,\n",
            "         -6.5440e-02, -4.8287e-04, -1.1179e-01, -1.6069e-01]])\n",
            "2.bias tensor([-0.0947])\n"
          ]
        }
      ]
    }
  ]
}